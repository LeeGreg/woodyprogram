# Readme

```java
// 如何介绍项目
1. 站在码农的角度介绍项目，专注技术指标以及解决思路
2. 自信，脉络要清晰：项目用途->自己的角色->如何解决难题
3. 项目若找不到难点，则谈谈改进，前提是熟悉相关涉及的知识点
4. 事前用图形将你的项目勾画清楚
// 编译java源文件
javac xxx.xxx.java
// 查看class文件内容
javap -verbose xxx.xxx.class
```



# 计算机网络

* OSI

* TCP
  * 传输控制协议TCP	
    - 面向连接的、可靠的、基于字节流的传输层通信协议
    - 将应用层的数据流分割成报文段并发送给目标节点的TCP层
    - 数据包都有序号，对方收到则发送ACK确认，未收到则重传
    - 使用校验和来检测数据在传输过程中是否有误
  * TCP Flags
    * ACK：确认序号标识
    * SYN：同步序号，用于建立连接过程
    * FIN：finish标志，用于释放连接
  * TCP三次握手建立连接
    * ![image-20190807104050540](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807104050540.png)
    * 第一次握手：客户端主动打开，发送SYN包（syn=j）到服务器，并进入SYN_SEND状态，等待服务器确认
    * 第二次握手：服务器收到SYN包，必须确认客户端的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态
    * 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK（ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手
  * TCP四次挥手释放连接
    * ![image-20190807104804128](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807104804128.png)
    * 第一次挥手：客户端发送一个FIN，用来关闭客户端到服务器的数据传递，客户端进入FIN_WAIT_1状态
    * 第二次挥手：服务器收到FIN后，发送一个ACK给客户端，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），服务器进入CLOSE_WAIT状态
    * 第三次挥手：服务器发送一个FIN，用来关闭服务器到客户端的数据传送，服务器进入LAST_ACK状态
    * 第四次挥手：客户端收到FIN后，客户端进入TIME_WAIT状态，接着发送一个ACK给服务器，确认序号为收到序号+1，服务器进入CLOSED状态，完成四次挥手
    * 为什么会有TIME_WAIT状态
      * 原因
        * 确保有足够的时间让对方接收到ACK包
        * 避免新旧连接混淆
    * 为什么需要四次握手才能断开
      * 因为全双工，发送方和接收方都需要FIN保文和ACK保文

* UDP
  * 面向非连接
  * 不维护连接状态，支持同时向多个客户端传输相同的信息
  * 数据包报头只有8个字节，额外开销较小
  * 吞吐量只受限于数据生成速率、传输速率以及及其性能
  * 尽最大努力交付，不保证可靠交付，不需要维持复杂的链接状态表
  * 面向报文，不对应用程序提交的报文信息进行拆分或者合并
  
* TCP和UDP区别
  
  * 是否面向连接、可靠性、有序性、速度、量级（TCP头部20字节，UDP8字节）
  
* TCP的滑动窗口
  - RTT：发送一个数据包到接收到对应的ACK，所花费的时间
  - RTO：重传时间间隔
  - 做流量控制和乱序排序
    - 保证TCP的可靠性
    - 保证TCP的流控特性

* HTTP超文本传输协议
  * 支持客户/服务器模式、简单快速、灵活、无连接、无状态
  * HTTP请求结构
    * HTTP请求报文
    * 请求行
      * 请求方法 空格 URL 空格 协议版本 回车符换行符
    * 请求头部
      * 头部字段名：值 回车符 换行符
      * 头部字段名：值 回车符 换行符
    * 回车符 换行符
    * 请求正文
  * HTTP响应结构
    * HTTP响应报文
    * 状态行
      * 协议版本 空格 状态码 空格 状态描述 回车符 换行符
    * 响应头部
      * 头部字段名：值 回车符 换行符
      * 头部字段名：值 回车符 换行符
    * 回车符 换行符
    * 响应正文
  * 请求/响应的步骤
    * 客户端连接到Web服务器
    * 发送HTTP请求
    * 服务器接收请求并返回HTTP响应
    * 释放连接TCP连接
    * 客户端浏览器解析HTML内容
  * 在浏览器地址栏输入URL按下回车后的经历的流程
    * DNS解析-TCP连接-发送HTTP请求-服务器处理请求并返回HTTP报文-浏览器解析渲染页面-连接结束
  * HTTP状态码
    * 200 OK 正常返回信息
    * 3xx，重定向，要完成请求必须进行更进一步的操作
    * 400 Bad Request，客户端请求有语法错误，不能被服务器所理解
    * 401 Unauthorized 请求未经授权
    * 403 Forbidden，服务器收到请求，但是拒绝提供服务
    * 404 Not Found，请求资源不存在
    * 500 Internal Server Error，服务器发生不可预测错误
    * 503 Server Unavailable，服务器当前不能处理客户端请求，一段时间后可恢复正常
  * GET请求和POST请求的区别
    * Http报文层面：GET将请求信息放在URL，POST放在报文体
    * 数据库层面：GET符合幂等性和安全性，POST不符合
    * 其他层面：GET可以被缓存、被存储，而POST不行
  * Cookie
    * 简介
      * 是由服务器发送给客户端的特殊信息，以文本的形式存放在客户端
      * 客户端再次请求的时候，会把Cookie回发
      * 服务器接收到后，会解析Cookie生成与客户端相对应的内容
    * Cookie的设置以及发送过程
      * 客户端发送Http Request给Web服务器
      * Web服务器返回Http Response 和set-Cookie:JSESESSION=xxx给客户端
      * 客户端发送Http Request 和Cookie:JSESESSION=xxx给服务器
      * 服务器返回Http Response
  * Session
    * 实现方式
      * 使用Cookie来实现
      * 使用URL回写来实现
  * Cookie和Session的区别
    * Cookie数据存放在客户的浏览器上，Session数据放在服务器上
    * Session相对于Cookie更安全
    * 若考虑减轻服务器负担，应当使用Cookie
  
* HTTPS
  * HTTP - SSL or TLS - TCP - IP
  * SSL安全套阶层，是操作系统对外的API，SSL3.0后更名为TLS，采用身份验证和数据加密保证网络通信的安全和数据的完整性
  * 加密方式
    * 对称加密：加密和解密都使用同一个密钥
    * 非对称加密：加密使用的密钥和解密使用的密钥是不相同的
    * 哈希算法：将任意长度的信息转换为固定长度的值，算法不可逆
    * 数字签名：证明某个消息或者文件是某人发出/认同的
  * HTTPS数据传输流程
    * 浏览器将支持的加密算法信息发送给服务器
    * 服务器选择一套浏览器支持的加密算法，以证书的形式回发浏览器
    * 浏览器验证证书合法性，并结合证书公钥加密信息发送给服务器
    * 服务器使用私钥解密信息，验证哈希，加密响应消息回发浏览器
    * 浏览器解密响应消息，并对消息进行验真，之后进行加密交互数据
  * HTTP和HTTPS的区别
    * HTTPS需要到CA申请证书，HTTP不需要
    * HTTPS密文传输，HTTP明文传输
    * 连接方式不同，HTTPS默认使用443端口，HTTP使用80端口
    * HTTPS=HTTP + 加密 + 认证 + 完整性保护，较HTTP安全
  * HTTPS真的很安全吗
    * 那倒未必
      * 浏览器默认填充http://，请求需要进行跳转，有被劫持的风险
      * 可以使用HSTS（HTTP Strict Transport Security）优化
  
* Socket

  * Socket是对TCP/IP协议的抽象，是操作系统对外开放的接口

  * ![image-20190807114545320](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807114545320.png)

  * 相关面试题

    * 编写一个网络应用程序，有客户端与服务器端，客户端向服务器发送一个字符串，服务器收到该字符串后将其打印到命令行上，然后向客户端返回改字符串的长度，最后，客户端输出服务器端返回的该字符串的长度，分别用TCP和UDP两种方式去实现

    * ```java
      public class LengthCalculator extends Thread {
          //以socket为成员变量
          private Socket socket;
      
          public LengthCalculator(Socket socket) {
              this.socket = socket;
          }
      
          @Override
          public void run() {
              try {
                  //获取socket的输出流
                  OutputStream os = socket.getOutputStream();
                  //获取socket的输入流
                  InputStream is = socket.getInputStream();
                  int ch = 0;
                  byte[] buff = new byte[1024];
                  //buff主要用来读取输入的内容，存成byte数组，ch主要用来获取读取数组的长度
                  ch = is.read(buff);
                  //将接收流的byte数组转换成字符串，这里获取的内容是客户端发送过来的字符串参数
                  String content = new String(buff, 0, ch);
                  System.out.println(content);
                  //往输出流里写入获得的字符串的长度，回发给客户端
                  os.write(String.valueOf(content.length()).getBytes());
                  //不要忘记关闭输入输出流以及socket
                  is.close();
                  os.close();
                  socket.close();
              } catch (IOException e) {
                  e.printStackTrace();
              }
          }
      }
      ```

      ```java
      public class TCPClient {
          public static void main(String[] args) throws Exception {
              //创建socket，并指定连接的是本机的端口号为65000的服务器socket
              Socket socket = new Socket("127.0.0.1", 65000);
              //获取输出流
              OutputStream os = socket.getOutputStream();
              //获取输入流
              InputStream is = socket.getInputStream();
              //将要传递给server的字符串参数转换成byte数组，并将数组写入到输出流中
              os.write(new String("hello world").getBytes());
              int ch = 0;
              byte[] buff = new byte[1024];
              //buff主要用来读取输入的内容，存成byte数组，ch主要用来获取读取数组的长度
              ch = is.read(buff);
              //将接收流的byte数组转换成字符串，这里是从服务端回发回来的字符串参数的长度
              String content = new String(buff, 0, ch);
              System.out.println(content);
              //不要忘记关闭输入输出流以及socket
              is.close();
              os.close();
              socket.close();
          }
      }
      ```

      ```java
      public class TCPServer {
          public static void main(String[] args) throws Exception {
              //创建socket,并将socket绑定到65000端口
              ServerSocket ss = new ServerSocket(65000);
              //死循环，使得socket一直等待并处理客户端发送过来的请求
              while (true) {
                  //监听65000端口，直到客户端返回连接信息后才返回
                  Socket socket = ss.accept();
                  //获取客户端的请求信息后，执行相关业务逻辑
                  new LengthCalculator(socket).start();
              }
          }
      }
      ```

      ```java
      public class UDPClient {
          public static void main(String[] args) throws Exception {
              // 客户端发数据报给服务端
              DatagramSocket socket = new DatagramSocket();
              // 要发送给服务端的数据
              byte[] buf = "Hello World".getBytes();
              // 将IP地址封装成InetAddress对象
              InetAddress address = InetAddress.getByName("127.0.0.1");
              // 将要发送给服务端的数据封装成DatagramPacket对象 需要填写上ip地址与端口号
              DatagramPacket packet = new DatagramPacket(buf, buf.length, address,
                      65001);
              // 发送数据给服务端
              socket.send(packet);
      
              // 客户端接受服务端发送过来的数据报
              byte[] data = new byte[100];
              // 创建DatagramPacket对象用来存储服务端发送过来的数据
              DatagramPacket receivedPacket = new DatagramPacket(data, data.length);
              // 将接受到的数据存储到DatagramPacket对象中
              socket.receive(receivedPacket);
              // 将服务器端发送过来的数据取出来并打印到控制台
              String content = new String(receivedPacket.getData(), 0,
                      receivedPacket.getLength());
              System.out.println(content);
          }
      }
      ```

      ```java
      public class UDPServer {
          public static void main(String[] args) throws Exception {
              // 服务端接受客户端发送的数据报
              DatagramSocket socket = new DatagramSocket(65001); //监听的端口号
              byte[] buff = new byte[100]; //存储从客户端接受到的内容
              DatagramPacket packet = new DatagramPacket(buff, buff.length);
              //接受客户端发送过来的内容，并将内容封装进DatagramPacket对象中
              socket.receive(packet);
              byte[] data = packet.getData(); //从DatagramPacket对象中获取到真正存储的数据
              //将数据从二进制转换成字符串形式
              String content = new String(data, 0, packet.getLength());
              System.out.println(content);
              //将要发送给客户端的数据转换成二进制
              byte[] sendedContent = String.valueOf(content.length()).getBytes();
              // 服务端给客户端发送数据报
              //从DatagramPacket对象中获取到数据的来源地址与端口号
              DatagramPacket packetToClient = new DatagramPacket(sendedContent,
                      sendedContent.length, packet.getAddress(), packet.getPort());
              socket.send(packetToClient); //发送数据给客户端
          }
      }
      ```

# 数据库

## 架构

* 如何设计一个关系型数据库
  * RDBMS
    * 程序实例
      * 存储管理、缓存机制、SQL解析、日志管理、权限划分、容灾机制、索引管理、锁管理
    * 存储（文件系统）

## 索引

* 为什么要使用索引

  - 快速查询数据，避免全表扫描

* 什么样的信息能够成为索引

  - 主键、唯一键以及普通键

* 索引的数据结构

  - 生成索引，建立二叉查找树进行二分查找
    - 每个节点最多有两个节点
    - 左子节点小于父节点，右子节点大于父节点
    - 平衡二叉树
    - 缺点：O(logn) - 会变成 - O(n)、树的深度会很深导致IO次数变多
  - 生成索引，建立B-Tree结构进行查找
    - B-Tree
      - 根节点至少包括两个孩子
      - 树中每个节点最多含有m个孩子(m >= 2)
      - 除根节点和叶节点外，其他每个节点至少有ceil(m/2)个孩子（ceil-取上）
      - 所有的叶子节点都位于同一层
      - ![image-20190807135334991](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807135334991.png)
      - ![image-20190807135404619](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807135404619.png)
  - 生成索引，建立B+-Tree结构进行查找
    - B+树是B树的变体，其定义基本与B树相同，除了：
      - 非叶子节点的子树指针与关键字个数相同
      - 非叶子节点的子树指针P[i]，指向关键字值[K[i], K[i+1])的子树
      - 非叶子节点仅用来索引，数据都保存在叶子节点中
      - 所有叶子节点均有一个链指针指向下一个叶子节点
      - ![image-20190807135854117](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807135854117.png)
    - B+Tree更适合用来做存储索引
      - B+树的磁盘读写代价更低
      - B+树的查询效率更加稳定
      - B+树更有利于对数据库的扫描
  - 生成索引，建立Hash结构进行查找
    - 仅能满足“=”，“IN”，不能使用范围查询
    - 无法被用来避免数据的排序操作
    - 不能利用部分索引键查询
    - 不能避免表扫描
    - 遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高

* 密集索引和稀疏索引的区别

  * 密集索引文件中的每个搜索码值都对应一个索引值
  * 稀疏索引文件只为索引码的某些值建立索引项

* InnoDB

  * 若一个主键被定义，该主键则作为密集索引
  * 若没有主键被定义，该表的第一个唯一非空索引则作为密集索引
  * 若不满足以上条件，innodb内部会生成一个隐藏主键（密集索引）
  * 非主键索引存储相关键位和其对应的主键值，包含两次查找

* innodb的索引和数据是存在一起的；MyISAM的索引和数据是分开存储的

* 如何定位并优化慢查询SQL

  * 具体场景具体分析，大致思路

  * 根据慢日志定位慢查询SQL

    * MySQL Console中执行：

    * `show variables like '%quer%';` 显示查询设置，关注下面三个

      * `long_query_time:10.000000`
      * `slow_query_log:OFF`
      * `slow_query_log_file:/var/lib/mysql/e1a7801d0387-slow.log`

    * `show status like '%slow_queries%;'`，显示慢查询SQL数

      * `Slow_queries:0`

    * 设置配置，重新连接后生效

      * 打开慢查询日志功能：`set global slow_query_log=on;`
      * 慢查询时间：`set global long_query_time=1;`

    * 查找具体慢查询SQL

      * 到`slow_query_log_file`设置的位置`/var/lib/mysql/e1a7801d0387-slow.log`中查看

        * docker中mysql

        * > docker container ls
          >
          > docker exec -it e1a7801d0387 bash
          >
          > cd /var/lib/mysql
          >
          > cat xxx.slow.log

  * 使用explain等工具分析SQL

    * `explain select name from person_info_large order by name desc`
      * 重点关注`type`和`extra`，type是index或all时需要优化
        * type：system>const>eq_ref>ref>fulltext>ref_or_null>index_merge>unique_subquery>index_subquery>range>index>all
        * extra需优化情况
          * Using filesort
            * 表示MySQL会对结果使用一个外部索引排序，而不是从表里按索引次序读到相关内容。可能在内存或磁盘上进行排序。MySQL中无法利用索引完成的排序操作称为文件排序
          * Using temporary
            * 表示MySQL在对查询结果排序时使用临时表，常见于排序order by和分组查询group by

  * 修改sql或尽量让sql走索引

    * ![image-20190807225222917](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807225222917.png)
    * `alter table person_info_large add index idx_name(name);`
    * ![image-20190807225637130](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807225637130.png)
    * ![image-20190807225857733](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807225857733.png)

* 联合索引的最左匹配原则的成因

  * 联合索引(a,b)，当where a = ''and b='' 或where a=''或where b=''and a=''时使用了联合索引；where b=''则没使用联合索引
  * ![image-20190807230307576](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807230307576.png)
  * ![image-20190807230704172](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190807230704172.png)
  * 先给最先的字段排序，然后在该字段基础上给接下来的字段排序

* 索引是建立越多越好吗

  * 数据量小的表不需要建立索引，建立会增加额外的索引开销
  * 数据变更需要维护索引，因此更多的索引意味着更多的维护成本
  * 更多的索引也意味着需要更多的空间

## 锁模块

* MyISAM与InnoDB关于锁方面的区别是什么

  * MyISAM默认用的是表级锁，不支持行级锁
  * InnoDB默认用的是行级锁，支持表级锁

* MyISAM

  - `select * from person where id between 1 and 2000000;`时会表锁 `update person set account = account  where id = 2000001;`会等待前面的select执行完才执行（如果是行级锁，则不会等待而是直接执行）
  - select时会加读锁，update需等待读锁释放后才加写锁进行数据更新
  - 显示加读锁/写锁：`lock tables person read | write;`
  - 释放读锁：`unlock tables;`
  - 读锁，也是共享锁；写锁，也是排他锁（读或写是不允许的）；
    - 除了给`insert、delete、update`加排他锁，也能给select加排他锁（`select ... for update;`）
  - 先加写锁，再加读锁，需先等待写锁释放后才能加读锁
    - `update person set account=account where id between 1 and 2000000;`
    - `select * from person where id in (2000000,2000001);`
  - 适合场景
    - 频繁执行全表count语句：不用扫描表，有个变量保存了整个表的行数，直接读取即可
    - 对数据进行增删改的频率不高，查询非常频繁
    - 没有事务

* InnoDB

  * `show variables like 'autocommit';`
  * 关闭自动提交，只对当前session有效`set autocommit=0`
  * InnoDB对select进行了改进：并未对select加读锁
  * 加共享锁：select .... lock in share mode;
  * InnoDB默认支持行级锁，不同行数据互不影响
  * InnoDB没有用到索引时，使用的是表级锁
  * 表级的意向锁
    - IS共享读锁、IX排他写锁
    - 与MyISAM的表锁差不多，表级别操作的时候不用去轮询每一行有没有上行锁
  * 适用场景
    - 数据增删改查都很频繁
    - 可靠性要求比较高，要求支持事务

* 数据库锁的分类

  - 按锁的粒度划分，可分为表级锁、行级锁、页级锁
  - 按锁级别划分，可分为共享锁、排他锁
  - 按加锁方式划分，可分为自动锁、显示锁
  - 按操作划分，可分为DML锁、DDL锁
  - 按使用方式划分，可分为悲观锁、乐观锁

* 数据库事务四大特性

  - 原子性（Atomic）
  - 一致性（Consistency）
  - 隔离性（Isolation）
    - 查看隔离级别`select @@tx_isolation`
    - 更改当前Session的隔离级别`set session transaction isolation level read uncommitted`
    - 持久性（Durability）

* 事务隔离级别以及各级别下的并发访问问题

  * 事务并发访问引起的问题以及如何避免

    - 更新丢失-MySQL所有事物隔离级别在数据库层面上均可避免

    - 脏读-READ-COMMITTED事务隔离级别以上均可避免

      - `start transaction;`
      - `sql...;`
      - `rollback; 或 commit;`

    - 不可重复读-REPEATABLE-READ事务隔离级别以上可避免

      - REPEATABLE-READ，sessionA在其事务期间多次读取的数据都是一样的，即使期间被其他事物修改并提交
      - sessionA在sessionB事务提交之前更改了数据
      - sessionB查询得到的一直是sessionA更改之前的数据，但是sessionB是在sessionA提交后的数据基础之上更新数据

    - 幻读-SERIALIABLE事务隔离级别可避免

    - - 幻读：事务A先查询（当前读-`select ... lock share in mode`）某范围内数据，事务B在该范围内新增或删除一条数据并提交，事务A再更新该范围内数据时会多或少更新数据
      - InnoDB的REPEATABLE-READ隔离级别可避免幻读

    - ![image-20190808070758066](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808070758066.png)

  * InnoDB可重复读隔离级别下如何避免幻读

    * 表象：快照读（非阻塞读）- 伪MVCC

    * - 当前读：共享锁和排他锁均为当前读，读取的是最新结果，并且读取后要保证其他并发事务不能修改结果，对结果加锁
        - `select ... lock in share mode`，共享锁
        - `select ... for update`，排他锁
        - `update、insert、delete`，排他锁
      - 快照读：不加锁的非阻塞读（SERIALIABLE级别的读是加锁的，为当前读模式select ... lock in share mode），select
        - 快照读是基于提升并发性能的考虑，是基于多版本并发控制MVCC来实现的，可以认为MVCC是行级锁的一个变种，在很多情况下避免加锁操作，开销更低，读取的可能不是最新版本而是历史版本
        - READ COMMITTED级别下，当前读和快照读的结果一致（事务期间读取到其他事物提交的最新结果）
        - READ REPEATBLE级别下，当前读读取的是最新数据，快照读可能读取的是历史版本数据（事务期间读取），快照创建的时期决定了事务读取的版本（快照读：sessionA期间先查询数据，sesionB更改并提交数据，sessionA再查询数据则为更改前的版本数据；sessionA先不查询数据，sessionB更改并提交数据，sessionA查询数据为最新版本数据）

    * 内在：next-key锁（行锁 + gap锁）
      - 行锁
      - gap锁（READ REPEATBLE、 SERIALIABLE）是个范围（左开右闭），不包括本身
        - 对主键索引或唯一索引会用gap锁吗？
          - 如果where条件全部命中，则不会用Gap锁、只会加记录锁
          - 如果where条件部分命中或者全不命中，则会加Gap锁
        - Gap锁会用在非唯一索引或者不走索引的当前读中
    * RC、RR级别下的InnoDB的非阻塞读如何实现
      - 数据行里的DB_TRX_ID（最后一次修改本行数据的事务ID）、DB_ROLL_PTR（回滚指针）、DB_ROW_ID字段
      - undo日志
        - insert undo log
        - update undo log：delete和update时
          - 更新数据时，首先用排他锁锁住某行数据，将该行数据拷贝一份到undo log，然后修改当前行的值，填写事务id，使用回滚指针（DB_ROLL_PTR）指向undo log中那条修改前的数据  
          - ![image-20190808212343234](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808212343234.png)
      - read view：可见性判断

* 语法部分

  - 关键语法（先根据需求列出sql子句，然后拼接）
    - Group By
      - 满足“SELECT 子句中的列名必须为分组列或列函数“
      - 列函数对于group by子句定义的每个组各返回一个结果
      - ![image-20190808220214233](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808220214233.png)
      - ![image-20190808220416827](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808220416827.png)
    - Having
      - 通常与Group By子句一起使用，指定Group By的过滤条件
      - where过滤行，Having过滤组；（如果省略了group by，那么having作用和where一样）
      - 出现在同一SQL中顺序：w here > group by > having
      - ![image-20190808220954877](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808220954877.png)
      - 统计相关：COUNT、SUM、MAX、MIN、AVG
      - ![image-20190808221240919](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808221240919.png)
      - ![image-20190808221352400](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808221352400.png)
    - 

# Redis

* 缓存中间件—Memcache和Redis的区别

  - Memcache代码层次类似Hash
    - 支持简单数据类型、不支持数据持久化存储、不支持主从、不支持分片
  - Redis
    - 数据类型丰富、支持数据磁盘持久化存储、支持主从、支持分片

* Redis为什么这么快

  - 完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高
  - 数据结构简单，对数据操作也简单
  - 采用单线程，单线程也能处理高并发请求，想多核也可启动多实例
    - 主线程是单线程，包括IO事件的处理、IO对应相关业务的处理、主线程还负责过期键的处理、复制协调、集群协调，这些除了IO事件之外的逻辑会被封装成周期性的任务由主线程周期性的处理，正因为采用单线程的处理，对于客户端的所有读写请求都由一个主线程串行处理，因此多个客户端同时对一个键进行写操作时就不会有并发的问题，避免了频繁的上下文切换和锁竞争，使得redis执行起来效率更高
  - 使用多路I/O复用模型，非阻塞IO

* 多路I/O复用模型

  - FD：File Descriptor，文件描述符
    - 一个打开的文件通过唯一的描述符进行引用，该描述符是打开文件的元数据到文件本身的映射
  - Select函数
    - 可以同时监控并返回多个文件描述符的读写情况
  - Redis采用的I/O多路复用函数：epoll/kqueue/evport/select？
    - 因地制宜，优先选择时间复杂度为O(1)的I/O多路复用函数作为底层实现
    - 以时间复杂度为O(n)的select作为保底
    - 基于react设计模式监听I/O事件

* Redis的数据类型

  - String，值最大512M，二进制安全（图片等），set
  - Hash，String元素组成的字典，适合用于存储对象，hset
  - List，按照String元素插入顺序排序，lpush
  - Set，String元素组成的无序集合，通过哈希表实现，不允许重复，sadd
  - Sorted Set，通过分数来为集合中的成员进行从小到大的排序，zadd

* 从海量key里查询出某一固定前缀的Key

  * > 批量生成redis测试数据 
    >
    > 1.Linux Bash下面执行 for((i=1;i<=20000000;i++)); do echo "set k$i v$i" >> /tmp/redisTest.txt ;done; 生成2千万条redis批量设置kv的语句(key=kn,value=vn)写入到/tmp目录下的redisTest.txt文件中 
    >
    > 2.用vim去掉行尾的^M符号，使用方式如下：： vim /tmp/redisTest.txt  :set fileformat=dos #设置文件的格式，通过这句话去掉每行结尾的^M符号  ::wq #保存退出 
    >
    > 3.通过redis提供的管道--pipe形式，去跑redis，传入文件的指令批量灌数据，需要花10分钟左右 cat /tmp/redisTest.txt | 路径/redis-5.0.0/src/redis-cli -h 主机ip -p 端口号 --pipe

  * 摸清数据规模，即问清楚边界，`dbsize返回key的数量`

  * keys pattern：查找所有符合给定模式pattern的key

    - keys指令一次性返回所有匹配的key
    - 键的数量过大会导致服务卡顿

  * `SCAN cursor [MATCH pattern] [COUNT count]`

    * 基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程
    * 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历
    * 不保证每次执行都返回某个给定数量的元素，支持模糊查询
    * 一次返回的数量不可控，只能是大概率符合count参数
    * ![image-20190808232453790](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808232453790.png)

* 如何通过redis实现分布式锁
  - 互斥性、安全性、死锁、容错
  - `SETNX key value`，如果key不存在则创建并赋值，时间复杂度O(1)，设置成功返回1，失败返回0
  - `EXPIRE key time`，单独都是原子操作，前后执行就可能不是原子操作
  - `SET key value [EX seconds] [PX milliseconds] [NX|XX]`
    - EX second：设置键的过期时间为second秒
    - PX millisecond：设置键的过期时间为milliseconds毫秒
    - NX：只在键不存在时，才对键进行设置操作
    - XX：只在键已经存在时，才对键进行设置操作
    - SET操作完成时，返回OK，否则返回nil
  - ![image-20190808233444983](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190808233444983.png)
  
* 大量的key同时过期的注意事项
  - 集中过期，由于清除大量的key很耗时，会出现短暂的卡顿现象
  - 解决方案：在设置key的过期时间时，给每个key加上随机值

* 如何使用Redis做异步队列
  * 使用List做队列，RPUSH生产消息，LPOP消费消息
    * 缺点：没有等待队列里有值就直接消费
    * 弥补：可以通过在应用层引入Sleep机制去调用LPOP重试
  * BLPOP key [key ...] timeout
    * 阻塞直到队列有消息或者超时
    * 缺点：只能供一个消费者消费
  * pub/sub：主题订阅者模式
    * 订阅者可以订阅多个频道
      * `subscribe topic`
      * `publish topic “hello”`
    * 缺点：消息的发布是无状态的，无法保证可达
  
* Redis如何持久化
  * RDB（快照）持久化：保存某个时间点的全量数据快照
    * SAVE：阻塞Redis的服务器进程，直到RDB文件被创建完毕
    * BGSAVE：Fork出一个子进程来创建RDB文件，不阻塞服务器进程
  * `lastsave`返回最近一次持久化成功的时间
    * 自动化触发RDB持久化的方式
      * 根据redis.conf配置里的SAVE m n定时触发（用的是BGSAVE）
      * 主从复制时，主节点自动触发
      * 执行Debug Reload
      * 执行Shutdown且没有开启AOF持久化
    * 缺点：
      * 内存数据的全量同步，数据量大会由于I/O而严重影响性能
      * 可能会因为Redis挂掉而丢失从当前至最近一次快照期间的数据
  * ![image-20190809162352367](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190809162352367.png)
    * Copy-on-Write
      * 如果有多个调用者同时要求相同资源（如内存或磁盘上的数据存储），它们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本给该调用者，而其他调用者所见到的最初的资源仍然保持不变
  * AOF（Append-Only-File）持久化：保存写状态
    * 记录下除了查询以外的所有变更数据库状态的指令
    * 以append的形式追加保存到AOF文件中（增量）
    * `redis.conf`
      - `appendonly yes`
      - `appendfsync everysec`
    * `config set appendonly yes`
  * 日志重写解决AOF文件大小不断增大的问题，原理如下：
    * 调用fork()，创建一个子进程
    * 子进程把新的AOF写到一个临时文件里，不依赖原来的AOF文件
    * 主进程持续将新的变动同时写到内存和原来的AOF里
    * 主进程获取子进程重写AOF的完成信号，往新AOF同步增量变动
    * 使用新的AOF文件替换掉旧的AOF文件
  * Redis数据恢复
    * ![image-20190809163555684](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190809163555684.png)
  * RDB和AOF的优缺点
    * RDB优点：全量数据快照，文件小、恢复快
    * RDB缺点：无法保存最近一次快照之后的数据
    * AOF优点：可读性高，适合保存增量数据，数据不易丢失
    * AOF缺点：文件体积大，恢复时间长
  * RDB - AOF混合持久化方式
    - BGSAVE做镜像全量持久化，AOF做增量持久化
  
* 使用Pipeline的好处

  * Pipeline和Linux的管道类似
  * Redis基于请求/响应模型，单个请求处理需要一一应答
  * Pipeline批量执行指令，节省多次IO往返的时间
  * 有顺序依赖的指令建议分批发送

* Redis的同步机制

  - 主从同步原理
    - 全同步过程
      - Salve发送sync命令到Master
      - Master启动一个后台进程，将Redis中的数据快照保存到文件中
      - Master将保存数据快照期间接收到的写命令缓存起来
      - Master完成写文件操作后，将该文件发送给Slave
      - 使用新的AOF文件替换掉旧的AOF文件
      - Master将这期间收集的增量写命令发送给Slave端
    - 增量同步过程
      - Master接收到用户的操作指令，判断是否需要传播到Slave
      - 将操作记录追加到AOF文件
      - 将操作传播到其他Slave：1、对齐主从库；2、往响应缓存写入指令
      - 将缓存中的数据发送给Slave

* Redis Sentinel

  * 解决主从同步Master宕机后的主从切换问题
    * 监控：检查主从服务器是否运行正常
    * 提醒：通过API向管理员或者其他应用程序发送故障通知
    * 自动故障迁移：主从切换

* 流言协议Gossip

  * 在杂乱无章中寻求一致
    * 每个节点都随机地与对方通信，最终所有节点的状态达成一致
    * 种子节点定期随机向其他节点发送节点列表以及需要传播的信息
    * 不保证信息一定会传递给所有节点，但是最终会趋于一致

* Redis的集群原理

  * 如何从海量数据里快速找到所需？
    * 分片：按照某种规则去划分数据，分散存储在多个节点上
    * 常规的按照哈希划分无法实现节点的动态增减
    * 一致性Hash算法：对2^32取模，将Hash值空间组织成虚拟的圆环
    * ![image-20190809165236475](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190809165236475.png)
    * 取服务器的主机名或IP进行Hash以确定每台服务器在Hash环上的位置
    * 对数据进行同样的hash算法去定位访问到相应的服务器，对数据key使用和服务器IP使用的相同的Hash函数计算出Hash值确定在环上的位置，顺时针遇到的第一个服务器即存储位置
    * 如果某个Node宕机，影响的是与其逆时针方向Node之间的数据，则其上数据会继续顺时针方向存储到相邻的节点上，影响最小化
    * 如果新增一个Node，受影响的是与其逆时针方向Node之间的数据，会存储到新的Node上
    * Hash环的数据倾斜问题：环上服务器数量少，大部分数据都存储在某一台上
      - 引入虚拟节点解决数据倾斜的问题
        - 对每一个服务器节点计算多个Hash，服务器节点的服务名或IP后增加编号

# JVM

* 谈谈对Java的理解
  
  * 平台无关性、GC、语言特性、面向对象、类库、异常处理
  
* “一次编译，到处运行”，如何实现
  * Java源码(.java文件)首先被编译（javac编译）成字节码（.class文件），再由不同平台的JVM进行解析
  * Java语言在不同的平台上运行时不需要进行重新编译，Java虚拟机在执行字节码的时候，把字节码转换成具体平台上的机器指令
  
* 为什么JVM不直接将源码解析成机器码去执行
  * 准备工作：每次执行都需要各种检查
  * 兼容性：也可以将别的语言解析成字节码
  
* JVM如何加载.class文件
  
  * ![image-20190809220541839](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190809220541839.png)
  
* 谈谈反射
  
  * 在运行状态中，对于任意一个类都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制
  
  * ```java
    public class Robot {
        private String name;
        public void sayHi(String helloSentence){
            System.out.println(helloSentence + " " + name);
        }
        private String throwHello(String tag){
            return "Hello " + tag;
        }
        static {
            System.out.println("Hello Robot");
        }
    }
    ```
  
    ```java
    public class ReflectSample {
        public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException, InvocationTargetException, NoSuchMethodException, NoSuchFieldException {
            Class rc = Class.forName("com.interview.javabasic.reflect.Robot");
            Robot r = (Robot) rc.newInstance();
            System.out.println("Class name is " + rc.getName());
            Method getHello = rc.getDeclaredMethod("throwHello", String.class);
            getHello.setAccessible(true);
            Object str = getHello.invoke(r, "Bob");
            System.out.println("getHello result is " + str);
            Method sayHi = rc.getMethod("sayHi", String.class);
            sayHi.invoke(r, "Welcome");
            Field name = rc.getDeclaredField("name");
            name.setAccessible(true);
            name.set(r, "Alice");
            sayHi.invoke(r, "Welcome");
            System.out.println(System.getProperty("java.ext.dirs"));
            System.out.println(System.getProperty("java.class.path"));
        }
    }
    ```
  
* 类从编译到执行的过程

  * 编译器将Java源文件编译为字节码文件
  * ClassLoader将字节码转换为JVM中的Class对象
  * JVM利用Class对象实例化为类对象

* 谈谈ClassLoader

  * 工作在Class装载的加载阶段，其主要作用是从系统外部获得Class二进制数据流，它是Java的核心组件，所有的Class都是由ClassLoader进行加载的，ClassLoader负责通过将Class文件里的二进制数据流装载进系统，然后交给Java虚拟机进行连接、初始化等操作

  * 种类

    * BootStrapClassLoader：C++编写，加载核心库java.*
    * ExtClassLoader：Java编写，加载扩展库javax.*
    * AppClassLoader：Java编写，加载程序所在目录
    * 自定义ClassLoader：Java编写，定制化加载

  * 自定义ClassLoader的实现

    * 关键函数

    * ```java
      protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
      }
      protected final Class<?> defineClass(byte[] b, int off, int len) throws ClassFormatError {
        return defineClass(null, b, off, len, null);
      }
      ```

    * 例子

    * ```java
      public class MyClassLoader extends ClassLoader {
          private String path;
          private String classLoaderName;
      
          public MyClassLoader(String path, String classLoaderName) {
              this.path = path;
              this.classLoaderName = classLoaderName;
          }
      
          //用于寻找类文件
          @Override
          public Class findClass(String name) {
              byte[] b = loadClassData(name);
              return defineClass(name, b, 0, b.length);
          }
      
          //用于加载类文件
          private byte[] loadClassData(String name) {
              name = path + name + ".class";
              InputStream in = null;
              ByteArrayOutputStream out = null;
              try {
                  in = new FileInputStream(new File(name));
                  out = new ByteArrayOutputStream();
                  int i = 0;
                  while ((i = in.read()) != -1) {
                      out.write(i);
                  }
              } catch (Exception e) {
                  e.printStackTrace();
              } finally {
                  try {
                      out.close();
                      in.close();
                  } catch (Exception e) {
                      e.printStackTrace();
                  }
              }
              return out.toByteArray();
          }
      }
      ```

      ```java
      public class ClassLoaderChecker {
          public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {
              MyClassLoader m = new MyClassLoader("/Users/baidu/Desktop/", "myClassLoader");
              Class c = m.loadClass("Wali");
              System.out.println(c.getClassLoader());
              System.out.println(c.getClassLoader().getParent());
              System.out.println(c.getClassLoader().getParent().getParent());
              System.out.println(c.getClassLoader().getParent().getParent().getParent());
              c.newInstance();
          }
      }
      ```

* 类加载器的双亲委派机制

  * 自底向上检查类是否已经加载
  * 自顶向下尝试加载类

* 为什么要使用双亲委派模式

  * 避免多份同样字节码的加载

* 类的加载方式

  * 隐式加载：new
  * 显示加载：loadClass，forName等

* 类的装载过程

  * 加载
    * 通过ClassLoader加载class文件字节码，生成Class对象
  * 链接
    * 校验：检查加载的class的正确性和安全性
    * 准备：为类变量分配存储空间并设置类变量初始值
    * 解析：JVM将常量池内的符号引用转换为直接引用
  * 初始化
    * 执行类变量赋值和静态代码块

* loadClass和forName的区别

  * Class.forName得到的class是已经初始化完成的
  * Classloader.loadClass得到的class是还没有链接的

* JVM内存模型-JDK8

  * 线程私有：
    * 程序计数器
      * 当前线程所执行的字节码行号指示器（逻辑）
      * 改变计数器的值来选取下一条需要执行的字节码指令
      * 对Java方法计数，如果是Native方法则计数器值为Undefined
      * 不会发生内存泄漏
    * 虚拟机栈
      * Java方法执行的内存模型
      * 包含多个栈帧：局部变量表（包含方法执行过程中的所有变量）、操作栈（入栈、出栈、复制、交换、产生消费变量）、动态链接、返回地址
      * 递归为什么会引发java.lang.StackOverflowError异常
        * 递归过深，栈帧数超出虚拟栈深度
        * 限制递归的次数
        * 虚拟机栈过多会引发java.lang.OutOfMemoryError异常
    * 本地方法栈
      * 与虚拟机栈相似，主要作用于标注了native的方法
  * 线程共享
    * MetaSpace
    * Java堆

* 元空间（MetaSpace）与永久代（PermGen）的区别
  * 元空间使用本地内存，而永久代使用的是jvm的内存
  * java.lang.OutOfMemeroyError:PermGen space
* MetaSpace相比PermGen的优势
  * 字符串常量池存在永久代中，容易出现性能问题和内存溢出
  * 类和方法的信息大小难以确定，给永久代的大小指定带来困难
  * 永久代会为GC带来不必要的复杂性
  * 方便HotSpot与其他JVM如Jrockit的集成
* Java的内存模型（Java堆-Heap）
  * 对象实例的分配区域
  * GC管理的主要区域
  * 新生代（Eden、survivor、survivor）和老年代
* JVM三大性能调优参数 -Xms -Xmx -Xss的含义
  * `java -Xms128m -Xmx128m -Xss256k -jar xxx.jar`
  * `-Xss`：规定了每个线程虚拟机栈（堆栈）的大小（会影响并发线程数的大小）
  * `-Xms`：堆的初始值
  * `-Xmx`：堆能达到的最大值
* Java内存模型中堆和栈的区别-内存分配策略
  * 静态存储：编译时确定每个数据目标在运行时的存储空间需求
  * 栈式存储：数据区需求在编译时未知，运行时模块入口前确定
  * 堆式存储：编译时或运行时模块入口都无法确定，动态分配
* Java内存模型中堆和栈的区别
  * 联系：引用对象、数组时，栈里定义变量保存堆中目标的首地址
    * 使用new开辟堆内存空间
    * 堆内存存储的是对象实例和数组
    * 栈内存存的是地址，指向对应堆内存空间
  * 管理方式：栈自动释放，堆需要GC
  * 空间大小：栈比堆小
  * 碎片相关：栈产生的碎片远小于堆
  * 分配方式：栈支持动态和静态分配，而堆仅支持动态分配
  * 效率：栈的效率比堆高

# GC

* 对象被判定为垃圾的标准
  - 没有被其他对象引用
* 判定对象是否为垃圾的算法
  - 引用计数算法
    - 通过判定对象的引用数量来决定对象是否可以被回收
    - 每个对象实例都有一个引用计数器，被引用则+1，完成引用则-1
    - 任何引用计数为0的对象实例可以被当作垃圾收集
    - 优点：执行效率高，程序执行受影响小
    - 缺点：无法检测出循环引用的情况，导致内存泄漏
  - 可达性分析算法
    - 通过判断对象的引用链是否可达来决定对象是否可以被回收
    - 可做GC Root的对象
      - 虚拟机栈中引用的对象（栈帧中的本地变量表）
      - 方法区中的常量引用的对象
      - 方法区中的类静态属性引用的对象
      - 本地方法栈中JNI（Native方法）的引用对象
      - 活跃线程的引用对象

* 垃圾回收算法
  - 标记-清除算法
    - 标记：从根集合进行扫描，对存活的对象进行标记
    - 清除：对堆内存从头到尾进行线性遍历，回收不可达对象内存
    - 缺点：碎片化
  - 复制算法
    - 分为对象面和空闲面，对象在对象面上创建
    - 存活的对象被从对象面复制到空闲面
    - 将对象面的所有对象内存清除
    - 适合对象存活率低的场景，如年轻代（10%的存活率）
    - 优点：解决碎片化问题、顺序分配内存，简单高效
  - 标记-整理算法
    - 标记：从根集合进行扫描，对存活的对象进行标记
    - 清除：移动所有存活的对象，且按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收
    - 优点：避免内存的不连续性、不用设置两块内存互换、适用于存活率高的场景（老年代）
  - 分代收集算法
    - 垃圾回收算法的组合拳（年轻代存活率低一般采用复制算法，老年代存活率高一般采用标记清除算法或标记整理算法）
    - 按照对象生命周期的不同划分区域以采用不同的垃圾回收算法
    - 目的：提高JVM的回收效率
    - ![image-20190810090622547](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190810090622547.png)

* GC的分类
  - Minor GC
  - Full GC
* 年轻代：尽可能快速的收集掉那些生命周期短的对象
  - Eden区
  - 两个Survivor区
  - ![image-20190810091315200](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190810091315200.png)

* 年轻代垃圾回收过程

  - 对象在Eden区出生并挤满Eden区，触发Minor GC将存活的对象复制到S0区并将年龄设置为1，清除所有的Eden区；然后Eden区再次被填满，触发Minor GC，将Eden和S0区存活的对象复制到S1并将年龄加1，清空Eden区和S0区；Eden区被填满，触发Minor GC，将Enen区和S1区存活的对象拷贝到S0区并且年龄加1，清空Eden和S1

* 对象如何晋升到老年代

  * 经历一定Minor次数依然活跃的对象
  * Survivor区中存放不下的对象
  * 新生成的大对象（-XX:+PretenuerSizeThreshold）

* 常用的调优参数

  * -XX:SurvivorRatio：Eden和Survivor的比值，默认8:1
  * -XX:NewRatio：老年代和年轻代内存大小的比例
  * -XX:MaxTenuringThreshold：对象从年轻代晋升到老年代经过GC次数的最大阀值

* 老年代：存放生命周期较长的对象

  * 标记-清理算法
  * 标记-整理算法

* 老年代

  - Full GC和Minor GC
  - Full GC比Minor GC慢，但执行频率低

* 触发Full GC的条件

  * 老年代空间不足、永久代空间不足、CMS GC时出现promotion failed，concurrent mode failure、Minor GC晋升到老年代的平均大小大于老年代的剩余空间、调用System.gc()、使用RMI来进行RPC或管理的JDK应用，每小时执行1次Full GC

* Stop-the-World

  * JVM由于要执行GC而停止了应用程序的执行
  * 任何一种GC算法中都会发生
  * 多数GC优化通过减少STW发生的时间来提高程序性能

* Safepoint

  * 分析过程中对象引用关系不会发生变化的点
  * 产生Safepoint的地方：方法调用；循环跳转；异常跳转等
  * 安全点数量得适中

* 常见的垃圾收集器

  - JVM的运行模式`java -version`
    - Server
      - 启动慢，运行一段时间稳定后速度较快，重量级虚拟机对程序进行了相应的优化
    - Client
      - 启动较快
  - ![image-20190810100709419](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190810100709419.png)
  - 年轻代常见的垃圾收集器
    - Serial收集器（-XX:+UseSerialGC，复制算法）
      - 单线程收集，进行垃圾收集时，必须暂停所有工作线程
      - 简单高效，Client模式下默认的年轻代收集器
      - 新生代采取复制算法暂停所有用户线程
    - ParNew收集器（-XX:+UseParNewGC，复制算法）
      - 多线程收集，其余的行为，特点和Serial收集器一样
      - 单核执行效率不如Serial，在多核下执行才有优势
      - 新生代采取复制算法暂停所有用户线程
    - Parallel Scavenge收集器（-XX:+UseParallelGC，复制算法）
      - 吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）
      - 比起关注用户线程停顿时间，更关注系统的吞吐量
      - 在多核下执行才有优势，Server模式下默认的年轻代收集器
      - 新生代采取复制算法暂停所有用户线程
      - -XX:+UseAdaptiveSizePolicy

  * 老年代常见的垃圾收集器
    * Serial Old收集器（-XX:+UseSerialOldGC，标记-整理算法）
      * 单线程收集，进行垃圾收集时，必须暂停所有工作线程
      * 简单高效，Client模式下默认的老年代收集器
      * 老年代采取标记-整理算法暂停所有用户线程
    * Parallel Old收集器（-XX:+UseParallelOldGC，标记-整理算法）
      * 多线程，吞度量优先
    * CMS收集器（-XX:+UseConcMarkSweepGC，标记-清除算法）
      * 垃圾回收线程和用户线程几乎可以做到同时工作
        - 初始化标记：会stop-the-world，扫描能和根对象关联的对象做标记，很快完成
        - 并发标记：并发追溯标记，程序不会停顿
        - 并发预清理：查找执行并发标记阶段从年轻代晋升到老年代的对象
        - 重新标记：暂停虚拟机，扫描CMS堆中的剩余对象
        - 并发清理：清理垃圾对象，程序不会停顿
        - 并发重置：重置CMS收集器的数据结构
    * G1收集器（-XX:+UseG1GC，复制+标记-整理算法）
      * 既能用于年轻代，又能用于老年代
      * 特点
        - 并发与并行
          - 使用多个CPU来缩短stop the world的时间，与用户并发执行
        - 分代收集
          - 独立管理整个堆，但是能够采用不同的方式去处理新创建的对象和已经存活一段时间并且经过多次GC的对象来达到更好的收集效果
        - 空间整合
          - 基于标记-整理算法，解决了内存碎片问题
        - 可预测的停顿
          - 可设置停顿时间
        - 将整个Java堆内存划分为多个大小相等的Region
          - 年轻代和老年代不再物理隔离

* Object的finalize()方法的作用是否与C++的析构函数作用相同

  * 与C++的析构函数不同，析构函数调用确定，而它的是不确定的
  * 将未被引用的对象放置于F-Queue队列
  * 方法执行随时可能会被终止
  * 给予对象最后一次重生的机会

* Java中的强引用、软引用、弱引用、虚引用有什么用？

  * 强引用

    * 抛出OutOfMemoryError终止程序也不会回收具有强引用的对象，Object obj = new Object();
    * 通过将对象设置为null来弱化引用，使其被回收

  * 软引用

    * 只有当内存空间不足时，GC会回收该引用的对象的内存
    * 可以用来实现高速缓存

  * 弱引用

    * GC时会被回收
    * 适用于引用偶尔被使用且不影响垃圾收集的对象

  * 虚引用

    * 不会决定对象的生命周期，任何时候都可能被垃圾收集器回收
    * 跟踪对象被垃圾收集器回收的活动，起哨兵作用
    * 必须和引用队列ReferenceQueue联合使用

  * ```java
    String str = new String("abc"); // 强引用
    SoftReference<String> softRef = new SoftReference<String>(str); //软引用
    WeakReference<String> weakRef = new WeakReference<String>(str); //弱引用
    ReferenceQueue queue = new ReferenceQueue();
    PhantomReference ref = new PhantomReference(str, queue);  //虚引用
    ```

  * ![image-20190810103912680](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190810103912680.png)

  * 引用队列

    * 无实际存储结构，存储逻辑依赖于内部节点之间的关系来表达
    * 存储关联的且被GC的软引用，弱引用以及虚引用
    * 外部可对ReferenceQueue进行监控，如果有对象即将被回收，相应的Reference对象将被放到该ReferenceQueue，然后就可以对Reference进行操作，如果不带ReferenceQueue，则会不断轮询Reference对象，通过判断get方法是否返回null来确认是否被回收了

  * ```java
    public class NormalObject {
        public String name;
        public NormalObject(String name){
            this.name = name;
        }
    
        @Override
        protected void finalize(){
            System.out.println("Finalizing obj " + name);
        }
    }
    ```

    ```java
    public class NormalObjectWeakReference extends WeakReference<NormalObject> {
        public String name;
    
        public NormalObjectWeakReference(NormalObject normalObject, ReferenceQueue<NormalObject> rq) {
            super(normalObject, rq);
            this.name = normalObject.name;
        }
        @Override
        protected void finalize(){
            System.out.println("Finalizing NormalObjectWeakReference " + name);
        }
    }
    ```

    ```java
    public class ReferenceQueueTest {
        private static ReferenceQueue<NormalObject> rq = new ReferenceQueue<NormalObject>();
    
        private static void checkQueue(){
            Reference<NormalObject> ref = null;
            while ((ref = (Reference<NormalObject>)rq.poll()) != null){
                if (ref != null){
                    System.out.println("In queue: " + ((NormalObjectWeakReference)(ref)).name);
                    System.out.println("reference object:" + ref.get());
                }
            }
        }
    
        public static void main(String[] args) {
            ArrayList<WeakReference<NormalObject>> weakList = new ArrayList<WeakReference<NormalObject>>();
            for (int i =0; i < 3 ; i++){
                weakList.add(new NormalObjectWeakReference(new NormalObject("Weak " + i),rq));
                System.out.println("Created weak:" + weakList.get(i));
            }
            System.out.println("first time");
            checkQueue();
            System.gc();
            try {
                Thread.currentThread().sleep(1000);
            } catch (InterruptedException e){
                e.printStackTrace();
            }
            System.out.println("second time");
            checkQueue();
        }
    }
    ```

    ![image-20190810105650499](/Users/dingyuanjie/Documents/study/github/woodyprogram/img/image-20190810105650499.png)

    